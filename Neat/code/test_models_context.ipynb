{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import model_from_json, Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation, multiply, BatchNormalization\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from pystoi.stoi import stoi\n",
    "import mir_eval #https://github.com/craffel/mir_eval\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from scipy.io import wavfile\n",
    "from natsort import natsorted\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab \n",
    "import soundfile as sf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define reconstruct function to reconstruct sound from framed signal.\n",
    "def reconstruct(wave,angle):\n",
    "    recon = np.sqrt(np.power(10, wave))\n",
    "    recon1 = recon*np.cos(angle)+recon*np.sin(angle)*1j\n",
    "    recon = librosa.core.istft((recon1.T), hop_length=256, win_length=512, window='hann')\n",
    "    return recon\n",
    "def change_order(first):\n",
    "    sec=np.copy(first)\n",
    "    sec=np.copy(first)\n",
    "    sec[0] = first[5]\n",
    "    sec[1] = first[4]\n",
    "    sec[2] = first[3]\n",
    "    sec[5] = first[2]\n",
    "    sec[4] = first[1]\n",
    "    sec[3] = first[0]\n",
    "    return sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_path = '/content/drive/My Drive/thesis/results'\n",
    "Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "batch_size = 32\n",
    "timestep = 16\n",
    "result_path = os.path.normpath(os.path.join(Data_path,'results'))\n",
    "seed = 7\n",
    "w=1\n",
    "np.random.seed(seed)\n",
    "result_path = os.path.normpath(os.path.join(Data_path,'results'))\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 106\n",
    "loaded_model.load_weights(os.path.normpath(os.path.join(Data_path,'models','model_'+str(model_num)+'.h5')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_ckpt(model_num):\n",
    "    h = [2048,2048,2048]\n",
    "    w=7\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(h[0], input_dim = w*257))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(h[1]))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(h[2]))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(257))\n",
    "    model.load_weights(os.path.normpath(os.path.join(Data_path,'checkpoints',str(model_num),'weights.11.hdf5')))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_num_classify= 109\n",
    "model_num_separate_male= 235\n",
    "model_num_separate_female= 235\n",
    "ckpt_num= '11'\n",
    "import tensorflow as tf\n",
    "import os\n",
    "Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "#either deine the model before or load it from a file here.\n",
    "def load_model(model_num):\n",
    "    Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "    json_file = open(os.path.normpath(os.path.join(Data_path,'models','model_'+str(model_num)+'.json')),'r')\n",
    "    print('blah')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights(os.path.normpath(os.path.join(Data_path,'models','model_'+str(model_num)+'.h5')))\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model\n",
    "\n",
    "\n",
    "model_classify = load_model(model_num_classify)\n",
    "foldername_classify = 'results_'+str(model_num_classify)+'_test'\n",
    "model_separate_male = load_model_ckpt(model_num_separate_male)\n",
    "foldername_separate_male = 'results_'+str(model_num_separate_male)+'_test_male'\n",
    "model_separate_female = load_model_ckpt(model_num_separate_female)\n",
    "foldername_separate_female = 'results_'+str(model_num_separate_female)+'_test_female'\n",
    "foldername_separate_both= 'results_'+str(model_num_separate_female)+'_'+str(model_num_separate_male)+'_test'\n",
    "#change directories for ur own code.\n",
    "Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "write_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff/testdata_30h'\n",
    "parent = 'results'\n",
    "input_test_ftr = 'ftr_refrmd_test_w7_norm_withtrain'\n",
    "input_test = 'test_log2_norm_withtrain'\n",
    "inputs = os.listdir(os.path.normpath(os.path.join(write_path,input_test)))\n",
    "inputs = natsorted(inputs)\n",
    "#there are different directories since there are different SNRs.\n",
    "if not os.path.exists(os.path.join(Data_path,parent,foldername_classify)):\n",
    "    os.makedirs(os.path.join(Data_path,parent,foldername_classify))\n",
    "if not os.path.exists(os.path.join(Data_path,parent,foldername_separate_male)):\n",
    "    os.makedirs(os.path.join(Data_path,parent,foldername_separate_male))\n",
    "if not os.path.exists(os.path.join(Data_path,parent,foldername_separate_female)):\n",
    "    os.makedirs(os.path.join(Data_path,parent,foldername_separate_female))\n",
    "if not os.path.exists(os.path.join(Data_path,parent,foldername_separate_both)):\n",
    "    os.makedirs(os.path.join(Data_path,parent,foldername_separate_both))\n",
    "predicts_snr = []\n",
    "for snr_input in inputs:\n",
    "    a = os.listdir(os.path.join(write_path,input_test,snr_input))\n",
    "    if not os.path.exists(os.path.join(Data_path,parent,foldername_classify,snr_input)):\n",
    "        os.mkdir(os.path.join(Data_path,parent,foldername_classify,snr_input))\n",
    "    if not os.path.exists(os.path.join(Data_path,parent,foldername_separate_male,snr_input)):\n",
    "        os.mkdir(os.path.join(Data_path,parent,foldername_separate_male,snr_input))\n",
    "    if not os.path.exists(os.path.join(Data_path,parent,foldername_separate_female,snr_input)):\n",
    "        os.mkdir(os.path.join(Data_path,parent,foldername_separate_female,snr_input))\n",
    "    if not os.path.exists(os.path.join(Data_path,parent,foldername_separate_both,snr_input)):\n",
    "        os.mkdir(os.path.join(Data_path,parent,foldername_separate_both,snr_input))\n",
    "    predicts = []\n",
    "    #predict the results base on the gender of the interferer.\n",
    "    for filename_input in a:\n",
    "        X_log=np.loadtxt(os.path.join(write_path,input_test,snr_input,filename_input),delimiter=',')\n",
    "        prediction = model_classify.predict(X_log)\n",
    "        for i in range(len(prediction)):\n",
    "            if prediction[i][0]>0.5:\n",
    "                prediction[i][0] = 1\n",
    "            else:\n",
    "                prediction[i][0] = 0\n",
    "        lst = 0\n",
    "        for i in range(len(prediction)):\n",
    "            lst = lst+prediction[i][0]\n",
    "        p_mean=lst/len(prediction)\n",
    "        predicts.append(p_mean)\n",
    "    predicts_snr.append(predicts)\n",
    "np.savetxt(os.path.join(Data_path,parent,foldername_classify,'predict_gender_before_thresh.txt'),predicts_snr, fmt='%1.2f')\n",
    "for i in range(len(predicts_snr)):\n",
    "    for j in range(len(predicts_snr[i])):\n",
    "        if predicts_snr[i][j]>0.5:\n",
    "            predicts_snr[i][j] = 1\n",
    "        else:\n",
    "            predicts_snr[i][j] = 0\n",
    "np.savetxt(os.path.join(Data_path,parent,foldername_classify,'predict_gender.txt'),predicts_snr, fmt='%1.0f')\n",
    "\n",
    "\n",
    "inputs = os.listdir(os.path.normpath(os.path.join(write_path,input_test_ftr)))\n",
    "inputs = natsorted(inputs)\n",
    "phase = os.listdir(os.path.join(write_path,'test_phase2'))\n",
    "phase = natsorted(phase)\n",
    "count_snr = 0\n",
    "for snr_input,snr_phase in zip(inputs,phase):\n",
    "    a = os.listdir(os.path.join(write_path,input_test_ftr,snr_input))\n",
    "    b = os.listdir(os.path.join(write_path,'test_phase2',snr_phase))\n",
    "    count_file = 0\n",
    "    for filename_input,filename_phase in zip(a,b):\n",
    "        X_log=np.loadtxt(os.path.join(write_path,input_test_ftr,snr_input,filename_input),delimiter=',')\n",
    "        X_phase=np.loadtxt(os.path.join(write_path,'test_phase2',snr_phase,filename_phase),delimiter=',')\n",
    "        if predicts_snr[count_snr][count_file]==0:\n",
    "            prediction = model_separate_male.predict(X_log)\n",
    "            recon_out = reconstruct(prediction, X_phase)\n",
    "            sf.write(os.path.normpath(os.path.join(Data_path,parent,foldername_separate_male,snr_input)+'\\\\'+filename_input.replace('.txt','')+'.wav'),recon_out,16000)\n",
    "        elif predicts_snr[count_snr][count_file]==1:\n",
    "            prediction = model_separate_female.predict(X_log)\n",
    "            recon_out = reconstruct(prediction, X_phase)\n",
    "            sf.write(os.path.normpath(os.path.join(Data_path,parent,foldername_separate_female,snr_input)+'\\\\'+filename_input.replace('.txt','')+'.wav'),recon_out,16000)\n",
    "        sf.write(os.path.normpath(os.path.join(Data_path,parent,foldername_separate_both,snr_input)+'\\\\'+filename_input.replace('.txt','')+'.wav'),recon_out,16000)\n",
    "        count_file +=1\n",
    "    count_snr +=1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
